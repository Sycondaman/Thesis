\clearpage\pagenumbering{roman}

\title{Massively Parallel Learning With an Application to Video Games}
\author{Tyler Goeringer}
\date{}
\advisorname{Soumya Ray}
\department{Electrical Engineering and Computer Science}
\maketitle


\committeechair{Soumya Ray}
\committeeb{Michael Lewicki}
\committeea{Swarup Bhunia}
\committeec{Frank Merat}
\committeeapprovalpage

\begin{acknowledgments}
    Acknowledgements will go here.
\end{acknowledgments}

\tableofcontents
\listoftables
\listoffigures

\begin{abbreviations}
    Abbreviations will go here.
\end{abbreviations}

\begin{umiabstract}
    In this project we propose a framework for periodic policy updates of computer controlled agents in an interactve scenario. The graphics processing unit (GPU) is used to accelerate an offline machine learning algorithm which periodically updates an online agent's policy. The main contributions of this work are the use of GPU acceleration combined with a periodic update model to provide reinforcement learning in a performance constrained environment. We show empirically that given certain environment properties, the GPU accelerated implementation provides better performance than a traditional implementation utilizing the computer processing unit (CPU). In addition, we show that while an online machine learning algorithm can function in some performance constrained environments, an offline algorithm reduces the performance constraints allowing for application to a wider variety of environments. Finally, we demonstrate combining these techniques to control an agent in the world of Quake III Arena, resulting in a computer controlled agent capable of adapting to different opponents.
\end{umiabstract}

\clearpage\pagenumbering{arabic}